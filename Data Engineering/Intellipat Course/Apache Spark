What is Apache Spark?

Writes an interface for programming multiple clusters with implicit data palrallelism and fault tolerance.

It provides real time computation and low latency because of in-memory computaion.
The in-memory cluster computation enables Spark to run iterative algorithms, as programs can checkpoint data and refer back to it without reloading it from disk; in addition it supports interactive querying and streaming data analysis at extremely fast speeds.

This makes it much faster in large scale applications.
It is Polyglot - meaning you can write applications in multiple languages such as java, scala, python , r and sql
Has multiple deployment nodes.

Spark Industry - Healthcare, media, finaince, ecommerce and travel etc

Spark + Hadoop:
Faster Analytics, Optimized costs, avoiding duplication. - organization in cloud help in all this

Scala 
Provides scalability ibn JVm
Higher performance
Excellent built-in concurrency support and libraries
Extremely fast and efficient

Architechture

                                                                    ----->  Worker/slave Node(Executor, Cache [task, task])
spark context (Driver Program)    -------------------> CLuster Manager  -----------
                                                                    ----->  Worker/slave Node(Executor, Cache [task, task])

Spark cluster manager types: Spark standalone cluster
                             Apache Mesos
                             Hadoop Yarn
                             Kurbenetes
Spark Shell - Scala
PySpark - Python
SparkR - R

RDDs - It is the fundamental data structure of Apache Spark.
In memory data sharing is much faster that disk or network
Resilient distributed dataset - it is fault tolerance, as it can recompute damaged partitions and node failures.

SPARK COMPONENTS
programming languages ---->     [SCALA]    [R]   [JAVA]    [PYTHON]
libraries  ----->      [SPARK_SQL]    [MLIIb]   [GRAPHX]  [STREAMING]
engine -------------------->           [SPARK_CORE]
cluster management ---> [HADOOP_YARN]    [APACHE_MESOS]    [SPARK_SCHEDULER]
storage ----->      [HDFS]    [STANDLONE_NODE]   [CLOUD]   [RDBMS/NOSQL] 