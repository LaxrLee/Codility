• Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
• Minimum two years’ experience in a data engineer role or similar.
• Experience with cloud data warehousing like snowflake.
• Advanced working SQL knowledge and experience working with relational databases, SQL as well as working familiarity with a variety of databases.
• Experience building and optimizing ‘big data’ data pipelines, architectures and data sets: i.e. Hadoop, Spark, Kafka, etc.
• Experience with relational SQL and NoSQL databases, including Postgres.
• Experience with data pipeline and workflow management tools: i.e. Azkaban, Luigi, Airflow, etc.
• Experience with object-oriented/object function scripting languages: i.e. Python, Java, etc.
• Strong analytic skills related to working with unstructured datasets.
• Strong project management and organizational skills.
• Experience supporting and working with cross-functional teams in a dynamic environment.
• High-level interpersonal and cross-cultural skills.
• Must be a self-starter and highly organized.
• Analytical, creative thinking and problem solving skills.
• Flexibility and adaptability.
• Open to change.
• Calm under chaos.