Building Data Pipelines - Extract, Transform, and Load

At the lowest level data engineers involves the movement of data from one system or 
format to another system or format.

When dealing with multiple databases, with different geographicaal locations - e,g retailers with 
different databases in different continents. 

How would you create connections to all of the transactional databases for each region, extract the data, and load it into a data warehouse. From there you can now count the item you want to know.
    We can find out which locations sell the most?
    Peak time for selling?
    How many users put the items in carts and remove them later?
    Combinations of items sold together?

It's more than just extracting data and loading it into a single system. 
We need to account for a bunch of things, such as timezones, we would need to transform the time fields to a standard.
We will also need to distinguish sales in each region. This could be accomplished by adding a new comlumn for location. Field should be spatial - in cordinates or as well-known text - or will just be text that could be transformed in a data engineering pipeline?

extract - transform - set the daata standards, for time, the international organization for standardization ISO 8601.
        Extract the data from each database
        add field to tag the location for each transaction in the data
        transfirm the date from local time to ISO 8601
        load the data into the data waregouse

This is accomplished by the creation of the data pipeline.
[source_data] --> [Extract] --> [Add_Location] --> [Transform_date] --> [Load] --> [Cleann_data]

Tools:
    Volume
    Variety
    Velocity
    Value
    Veracity

Dbs - Proprietary softwater - Oracle or Microsoft SQL Server
    - OpenSource software - MySQL or PostgreSQL

Common Dbs used in data warehousing are Amazon Redshift, Google BigQuery, Apache Cassandra, and other NoSQL dbs, such as Elasticsearch.
They deviate from traditional rows of relational databases and store data in a columnar format, 

Columnar dbs are better suited fir fast queries - making them well suited for data warehouses.
In contrast to columnar dbs, there are document or NoSQL dbs such as elasticsearch which is actually a search engine based on Apache Lucene/  Which is similar to Apache Solr.
Elasticsearch is open soource but does have propreitary components, like X-Pack plugins for machine learning, graphs, security, alert/monitring.
It uses DSL(Domain-Specific Language). Not SQL, but rather JSON queryt. It stores data as documents, and while it has parent-child documents, it is non-relational(like columbnar db).


Data Processing Engines
Engines allows us to transform data whether it is in batches or streams. Apache Spark is the most popular.
Spark has Resilient Distributed Datasets(RDDs). RDDs are an immutable and distributed collection of objects.